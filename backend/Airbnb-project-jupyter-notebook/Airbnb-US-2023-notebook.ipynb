{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45755d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Airbnb-US-2023.csv\")\n",
    "# Give some columns clearer/shorter names\n",
    "df = df.rename(columns={\n",
    "    \"price\": \"price_per_night\",\n",
    "    \"number_of_reviews\": \"nr_of_reviews\",\n",
    "    \"last_review\": \"last_review_date\",\n",
    "    \"calculated_host_listings_count\": \"nr_of_listings_by_host\",\n",
    "    \"availability_365\": \"days_per_year_available\",\n",
    "    \"number_of_reviews_ltm\": \"nr_of_reviews_last_twelve_months\"\n",
    "})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34a3e3",
   "metadata": {},
   "source": [
    "## Visualizing the locations\n",
    "### Use the output of the function below with google my maps to plot a number of locations unto a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4faf023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_locations_to_google_my_maps(dataframe, number_of_locations = 10000):\n",
    "    \"\"\"Extracts latitude, longitude, name, and room_type from the dataframe provided.\n",
    "    The locations are reduced until their number is close to number_of_locations.\n",
    "    The result is grouped based on room_type, each group is exported to multiple csv files of max length = 2000.\n",
    "    These are to be imported on Google My Maps for plotting.\"\"\"\n",
    "    \n",
    "    dataframe = dataframe[[\"latitude\", \"longitude\", \"name\", \"room_type\"]]\n",
    "    \n",
    "    entire_apartment_df = dataframe[dataframe[\"room_type\"] == \"Entire home/apt\"].drop(\"room_type\", axis=1)\n",
    "    private_room_df = dataframe[dataframe[\"room_type\"] == \"Private room\"].drop(\"room_type\", axis=1)\n",
    "    shared_room_df = dataframe[dataframe[\"room_type\"] == \"Shared room\"].drop(\"room_type\", axis=1)\n",
    "    hotel_room_df = dataframe[dataframe[\"room_type\"] == \"Hotel room\"].drop(\"room_type\", axis=1)\n",
    "    \n",
    "    locations_to_eliminate = len(dataframe) - number_of_locations\n",
    "    entire_apartment_ratio = len(entire_apartment_df) / len(dataframe)\n",
    "    private_room_ratio = len(private_room_df) / len(dataframe)\n",
    "    shared_room_ratio = len(shared_room_df) / len(dataframe)\n",
    "    hotel_room_ratio = len(hotel_room_df) / len(dataframe)\n",
    "    \n",
    "    entire_apartment_locations_to_delete = int(entire_apartment_ratio * locations_to_eliminate)\n",
    "    private_room_locations_to_delete = int(private_room_ratio * locations_to_eliminate)\n",
    "    shared_room_locations_to_delete = int(shared_room_ratio * locations_to_eliminate)\n",
    "    hotel_room_locations_to_delete = int(hotel_room_ratio * locations_to_eliminate)\n",
    "    \n",
    "    entire_apartment_locations_to_keep = len(entire_apartment_df) - entire_apartment_locations_to_delete\n",
    "    private_room_locations_to_keep = len(private_room_df) - private_room_locations_to_delete\n",
    "    shared_room_locations_to_keep = len(shared_room_df) - shared_room_locations_to_delete\n",
    "    hotel_room_locations_to_keep = len(hotel_room_df) - hotel_room_locations_to_delete\n",
    "    \n",
    "    entire_apartment_df_shortened = entire_apartment_df.sample(entire_apartment_locations_to_keep)\n",
    "    private_room_df_shortened = private_room_df.sample(private_room_locations_to_keep)\n",
    "    shared_room_df_shortened = shared_room_df.sample(shared_room_locations_to_keep)\n",
    "    hotel_room_df_shortened = hotel_room_df.sample(hotel_room_locations_to_keep)\n",
    "    \n",
    "    entire_apartment_dfs = np.array_split(entire_apartment_df_shortened, len(entire_apartment_df_shortened) // 2000 + 1)\n",
    "    for i, df_chunk in enumerate(entire_apartment_dfs):\n",
    "        df_chunk.to_csv(f\"google-my-maps-csvs/apartment{i}.csv\")\n",
    "    \n",
    "    private_room_dfs = np.array_split(private_room_df_shortened, len(private_room_df_shortened) // 2000 + 1)\n",
    "    for i, df_chunk in enumerate(private_room_dfs):\n",
    "        df_chunk.to_csv(f\"google-my-maps-csvs/private{i}.csv\")\n",
    "    \n",
    "    shared_room_dfs = np.array_split(shared_room_df_shortened, len(shared_room_df_shortened) // 2000 + 1)\n",
    "    for i, df_chunk in enumerate(shared_room_dfs):\n",
    "        df_chunk.to_csv(f\"google-my-maps-csvs/shared{i}.csv\")\n",
    "    \n",
    "    hotel_room_dfs = np.array_split(hotel_room_df_shortened, len(hotel_room_df_shortened) // 2000 + 1)\n",
    "    for i, df_chunk in enumerate(hotel_room_dfs):\n",
    "        df_chunk.to_csv(f\"google-my-maps-csvs/hotel{i}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac55520",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "### Removing duplicates and irrelevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9b8c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Length before removing duplicates: {len(df)}\")\n",
    "relevant_df = df.drop([\"id\"], axis=1)\n",
    "relevant_df = relevant_df.drop_duplicates()\n",
    "# We drop neighbourhood_group because we already have the neighbourhood column which provides more information\n",
    "relevant_df = relevant_df.drop([\"host_id\", \"host_name\", \"latitude\", \"longitude\", \"neighbourhood_group\"], axis=1)\n",
    "print(f\"Length after removing duplicates: {len(relevant_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ad61b",
   "metadata": {},
   "source": [
    "### Dealing with missing values and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ae120",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "relevant_df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56e0e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Length before removing irrelevant columns: {len(relevant_df)}\")\n",
    "non_null_df = relevant_df.copy()\n",
    "non_null_df = non_null_df.dropna(subset=[\"name\"])\n",
    "non_null_df.last_review_date = non_null_df.last_review_date.fillna(0)\n",
    "non_null_df.reviews_per_month = non_null_df.reviews_per_month.fillna(0)\n",
    "non_null_df.loc[non_null_df.last_review_date != 0, \"last_review_date\"] = pd.to_datetime(non_null_df[non_null_df.last_review_date != 0].last_review_date).apply(lambda x: int(x.timestamp()))\n",
    "print(f\"Length after removing irrelevant columns: {len(non_null_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c4e66",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a histogram of every column that could have outliers to see which ones have outliers\n",
    "# Alongside there will be plotted 2 vertical lines representing the bounds for eliminating outliers\n",
    "columns_used_for_checking_outliers = non_null_df.drop([\"name\", \"neighbourhood\", \"room_type\", \"city\"], axis=1).columns\n",
    "\n",
    "rows_of_subplots = int(len(columns_used_for_checking_outliers) / 2)\n",
    "columns_of_subplots = 2\n",
    "\n",
    "fig, axes = plt.subplots(rows_of_subplots, columns_of_subplots, figsize=(14, 10))\n",
    "fig.subplots_adjust(hspace=0.9, wspace=0.2)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for subplot_index, column_name in enumerate(columns_used_for_checking_outliers):\n",
    "    ax = axes[subplot_index]\n",
    "    ax.hist(non_null_df[column_name], bins=20, rwidth=0.8)\n",
    "    \n",
    "    mean = non_null_df[column_name].mean()\n",
    "    standard_deviation = non_null_df[column_name].std()\n",
    "    \n",
    "    lower_bound = mean - (3 * standard_deviation)\n",
    "    upper_bound = mean + (3 * standard_deviation)\n",
    "\n",
    "    ax.axvline(x=lower_bound, color='b')\n",
    "    ax.axvline(x=upper_bound, color='b')\n",
    "    \n",
    "    # most subplots need to be scaled logarithmically because there is one range of values that is much more frequent\n",
    "    # than any other, thus the subplot won't give too much information unless it is scaled\n",
    "    if column_name != \"days_per_year_available\":\n",
    "        ax.set_yscale(\"log\")\n",
    "    \n",
    "    ax.set_xlabel(column_name)\n",
    "    ax.set_ylabel(\"frequency\")\n",
    "    ax.set_title(f\"Distribution of {column_name}\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522fa64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# last_review_date and days_per_year_available will be excluded from outlier removal because they don't have any outliers\n",
    "\n",
    "columns_used_for_removing_outliers = non_null_df.drop([\"name\", \"neighbourhood\", \"room_type\", \"city\", \"last_review_date\", \"days_per_year_available\"], axis=1).columns\n",
    "\n",
    "print(f\"Length before removing outliers: {len(non_null_df)}\\n\")\n",
    "\n",
    "no_outliers_df = non_null_df.copy()\n",
    "\n",
    "for column_name in columns_used_for_removing_outliers:\n",
    "    mean = no_outliers_df[column_name].mean()\n",
    "    standard_deviation = no_outliers_df[column_name].std()\n",
    "    \n",
    "    lower_bound = mean - (3 * standard_deviation)\n",
    "    upper_bound = mean + (3 * standard_deviation)\n",
    "    \n",
    "    percentage_removed = round((((no_outliers_df[column_name] < lower_bound) | (no_outliers_df[column_name] > upper_bound)).sum() / len(no_outliers_df)) * 100, 2)\n",
    "\n",
    "    print(f\"For column {column_name}, removing a percentage of {percentage_removed}% values.\")\n",
    "    no_outliers_df = no_outliers_df[(lower_bound <= no_outliers_df[column_name]) & (no_outliers_df[column_name] <= upper_bound)]\n",
    "\n",
    "print(f\"\\nLength after removing outliers: {len(no_outliers_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27147bdd",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0721cf2",
   "metadata": {},
   "source": [
    "### Extracting meaningful words from name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d81f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_meaningful_words_df = no_outliers_df.copy()\n",
    "name_meaningful_words_df.name = no_outliers_df.name.str.lower()\n",
    "# Extract number of bedrooms in a separate column\n",
    "name_meaningful_words_df[\"nr_of_bedrooms\"] = name_meaningful_words_df.name.str.extract('(\\d+)\\s*-?\\+?(?:br|bd|bed)')\n",
    "name_meaningful_words_df[\"has_nr_of_bedrooms\"] = ~name_meaningful_words_df[\"nr_of_bedrooms\"].isnull()\n",
    "name_meaningful_words_df[\"nr_of_bedrooms\"] = name_meaningful_words_df[\"nr_of_bedrooms\"].fillna(0)\n",
    "\n",
    "def most_frequent_words_in_name_column(dataframe):\n",
    "    # filter anything that is not helpful, or any words that are related to location\n",
    "    filtered_strings = {\"in\", \"private\", \"to\", \"bedroom\", \"the\", \"room\", \"home\", \"with\", \"apartment\", \"near\", \"and\", \"house\", \"of\", \n",
    "    \"a\", \"from\", \"bed\", \"apt\", \"bath\", \"close\", \"view\", \"suite\", \"on\", \"walk\", \"location\", \"for\", \"east\", \"by\", \"at\", \"hollywood\", \n",
    "    \"city\", \"one\", \"austin\", \"unit\", \"br\", \"nr\", \"west\", \"s\", \"d\", \"dt\", \"no\", \"bd\", \"b\", \"la\", \"full\", \"brooklyn\", \"san\", \"brand\", \n",
    "    \"hill\", \"steps\", \"minutes\", \"bathroom\", \"strip\", \"vegas\", \"manhattan\", \"prime\", \"las\", \"hills\", \"south\", \"mins\", \"hot\", \"guest\", \n",
    "    \"two\", \"free\", \"min\", \"hotel\", \"nyc\", \"place\", \"w\", \"floor\", \"stay\", \"nashville\", \"space\", \"shared\", \"away\", \"north\", \"entire\", \n",
    "    \"beds\", \"sleeps\", \"bay\", \"williamsburg\", \"side\", \"living\", \"kitchen\", \"rental\", \"square\", \"district\", \"located\", \"street\", \"area\", \"your\", \n",
    "    \"upper\", \"neighborhood\", \"pet\", \"st\", \"bdrm\", \"venice\", \"los\", \"style\", \"santa\", \"bedrooms\", \"blocks\", \"heights\", \"diego\", \n",
    "    \"block\", \"next\", \"miles\", \"capitol\", \"long\", \"centre\", \"dtla\", \"top\", \"broadway\", \"seattle\", \"mission\", \"all\"}\n",
    "\n",
    "    word_frequencies = no_outliers_df.name.str.split('\\\\W+', expand=True).stack().value_counts()\n",
    "    word_frequencies = word_frequencies[(word_frequencies >= 1000) & word_frequencies.index.str.isalpha()]\n",
    "    word_frequencies = word_frequencies[~word_frequencies.index.isin(filtered_strings)]\n",
    "    \n",
    "    return word_frequencies\n",
    "\n",
    "most_frequent_words_in_name_column(name_meaningful_words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent words have to be manually extracted because similar words were grouped together to reduce number of columns\n",
    "# And some were removed due to not being useful\n",
    "meaningful_words_with_column_name = [\n",
    "    [\"peaceful\", [\"quiet\", \"oasis\", \"retreat\", \"getaway\", \"peaceful\"]],\n",
    "    [\"luxurios\", [\"luxury\", \"luxurious\", \"resort\", \"deluxe\"]],\n",
    "    [\"lovely\", [\"lovely\", \"charming\", \"cute\", \"nice\"]],\n",
    "    [\"spacious\", [\"spacious\", \"large\", \"huge\", \"big\"]],\n",
    "    [\"comfortable\", [\"cozy\", \"comfy\", \"comfortable\"]],\n",
    "    [\"central\", [\"downton\", \"heart\", \"central\", \"midtown\"]],\n",
    "    [\"amazing\", [\"great\", \"amazing\", \"best\", \"perfect\", \"paradise\"]],\n",
    "    [\"beautiful\", [\"beautiful\", \"gorgeous\", \"stunning\"]],\n",
    "    [\"bright\", [\"sunny\", \"bright\", \"cheerful\"]],\n",
    "    [\"renovated\", [\"renovated\", \"remodeled\", \"newly\"]],\n",
    "    [\"backyard\", [\"garden\", \"backyard\", \"yard\"]],\n",
    "    [\"beach\", [\"beach\", \"ocean\"]],\n",
    "    [\"pool\", [\"pool\", \"tub\"]],\n",
    "    [\"patio\", [\"deck\", \"patio\"]],\n",
    "    [\"stylish\", [\"stylish\", \"chic\"]],\n",
    "    [\"convenient\", [\"convenient\", \"everything\"]],\n",
    "    [\"townhouse\", [\"townhouse\", \"townhome\"]],\n",
    "    [\"urban\", [\"urban\", \"town\",]],\n",
    "    [\"modern\", [\"modern\", \"new\",]],\n",
    "    [\"village\", [\"village\"]],\n",
    "    [\"cottage\", [\"cottage\"]],\n",
    "    [\"studio\", [\"studio\"]],\n",
    "    [\"condo\", [\"condo\"]],\n",
    "    [\"bungalow\", [\"bungalow\"]],\n",
    "    [\"villa\", [\"villa\"]],\n",
    "    [\"penthouse\", [\"penthouse\"]],\n",
    "    [\"duplex\", [\"duplex\"]],\n",
    "    [\"loft\", [\"loft\"]],\n",
    "    [\"king\", [\"king\"]],\n",
    "    [\"queen\", [\"queen\"]],\n",
    "    [\"master\", [\"master\"]],\n",
    "    [\"gym\", [\"gym\"]],\n",
    "    [\"entrance\", [\"entrance\"]],\n",
    "    [\"balcony\", [\"balcony\"]],\n",
    "    [\"rooftop\", [\"rooftop\"]],\n",
    "    [\"mid\", [\"mid\"]],\n",
    "    [\"victorian\", [\"victorian\"]],\n",
    "    [\"historic\", [\"historic\"]],\n",
    "    [\"gem\", [\"gem\"]],\n",
    "    [\"clean\", [\"clean\"]],\n",
    "    [\"furnished\", [\"furnished\"]],\n",
    "    [\"family\", [\"family\"]],\n",
    "    [\"friendly\", [\"friendly\"]],\n",
    "    [\"views\", [\"views\"]],\n",
    "    [\"valley\", [\"valley\"]],\n",
    "    [\"park\", [\"park\"]],\n",
    "    [\"lake\", [\"lake\"]],\n",
    "    [\"waterfront\", [\"waterfront\"]],\n",
    "    [\"vacation\", [\"vacation\"]],\n",
    "    [\"spa\", [\"spa\"]],\n",
    "    [\"heated\", [\"heated\"]],\n",
    "    [\"airport\", [\"airport\"]],\n",
    "    [\"parking\", [\"parking\"]],\n",
    "    [\"wifi\", [\"wifi\"]]\n",
    "]\n",
    "\n",
    "for column_name, values_to_search in meaningful_words_with_column_name:\n",
    "    name_meaningful_words_df[column_name] = name_meaningful_words_df.name.str.split('\\\\W+').apply(lambda cur_word: any(value_to_search in cur_word for value_to_search in values_to_search))\n",
    "\n",
    "name_meaningful_words_df.to_csv(\"it_did_go_well.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0636d963",
   "metadata": {},
   "outputs": [],
   "source": [
    "something_export = no_outliers_df[no_outliers_df.name.str.contains(\"\\d\")]\n",
    "something_export.to_csv(\"something_something.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71844cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "something = no_outliers_df.copy()\n",
    "something[\"nr_of_bedrooms\"] = something.name.str.extract('(\\d+)\\s*-?\\+?(?:br|bd|bed)', expand=False)\n",
    "something[\"has_nr_of_bedrooms\"] = ~something[\"nr_of_bedrooms\"].isnull()\n",
    "something[\"nr_of_bedrooms\"] = something[\"nr_of_bedrooms\"].fillna(0)\n",
    "something.to_csv(\"nr_of_bedrooms.csv\")\n",
    "something"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e6299",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5328cef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# One-hot encoding the room_type, city and neighbourhood columns\n",
    "room_type_dummies = pd.get_dummies(no_outliers_df.room_type, drop_first=True)\n",
    "city_dummies = pd.get_dummies(no_outliers_df.city, drop_first=True)\n",
    "#neighbourhood_dummies = pd.get_dummies(no_outliers_df.neighbourhood, drop_first=True)\n",
    "#final_df = pd.concat([no_outliers_df, room_type_dummies, city_dummies, neighbourhood_dummies], axis=\"columns\")\n",
    "final_df = pd.concat([no_outliers_df, room_type_dummies, city_dummies], axis=\"columns\")\n",
    "final_df = final_df.drop([\"neighbourhood\", \"room_type\", \"city\"], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c13e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe374e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c01abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X = final_df.drop(\"price_per_night\", axis=1)\n",
    "y = final_df.price_per_night\n",
    "\n",
    "models = {\n",
    "  'linear_regression': {\n",
    "    'steps': [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('regressor', linear_model.LinearRegression())\n",
    "    ],\n",
    "    'params': {}\n",
    "  }\n",
    "}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, options in models.items():\n",
    "    print(f\"checking model {model_name}\")\n",
    "    pipeline = Pipeline(options[\"steps\"])\n",
    "    grid_search = GridSearchCV(pipeline, options[\"params\"], cv=5, return_train_score=False, verbose = 4)\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dc6634",
   "metadata": {},
   "source": [
    "## Testing ml models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db36a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X = final_df.drop(\"price_per_night\", axis=1)\n",
    "y = final_df.price_per_night\n",
    "\n",
    "models = {\n",
    "  'linear_regression': {\n",
    "    'steps': [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('regressor', linear_model.LinearRegression())\n",
    "    ],\n",
    "    'params': {}\n",
    "  },\n",
    "  'suppor_vector_regression': {\n",
    "    'steps': [\n",
    "        ('scaler', MinMaxScaler()),\n",
    "        ('regressor', SVR())\n",
    "    ],\n",
    "    'params': {\n",
    "        'regressor__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'regressor__C': [0.1, 10],\n",
    "        'regressor__epsilon': [0.1, 0.001],\n",
    "        'regressor__gamma': ['scale', 'auto']\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "scores = []\n",
    "\n",
    "for model_name, options in models.items():\n",
    "    print(f\"checking model {model_name}\")\n",
    "    pipeline = Pipeline(options[\"steps\"])\n",
    "    grid_search = GridSearchCV(pipeline, options[\"params\"], cv=5, return_train_score=False, verbose = 4)\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23a795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
